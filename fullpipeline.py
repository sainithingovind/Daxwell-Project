# -*- coding: utf-8 -*-
"""fullpipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bfniLkfjGdFFA6Kr2-H-aUfyfZwDPmdV
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
End-to-end IMDB Sentiment Pipeline (Daxwell-ready)

Features
- Data: Hugging Face IMDB or CSV (columns: text, label)
- Classic branch: TF-IDF -> GBT (XGBoost), Logistic Regression, optional MLP via SVD (RAM-safe)
- Transformer branch: DistilBERT fine-tune on subset
- Metrics: acc, f1, auc  -> saved to reports/metrics.csv
- Artifacts: models/, vectorizers/, transformer/
- Optional MLflow logging (local ./mlruns)

Usage examples:
  python full_pipeline.py --source imdb --run-gbt --run-logreg --use-mlflow
  python full_pipeline.py --source imdb --run-gbt --run-logreg --run-mlp-svd --svd-components 256
  python full_pipeline.py --source imdb --run-transformer --transformer-samples 4000 --transformer-epochs 1
  python full_pipeline.py --source csv --train-csv train.csv --test-csv test.csv --run-gbt --use-mlflow
"""

import os, re, html, argparse, random, warnings
from typing import Dict, Any, List, Tuple

import numpy as np
import pandas as pd

from joblib import dump
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import StandardScaler

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

# -----------------------------
# Utilities
# -----------------------------
def ensure_dirs():
    os.makedirs("models", exist_ok=True)
    os.makedirs("vectorizers", exist_ok=True)
    os.makedirs("reports", exist_ok=True)
    os.makedirs("transformer/model", exist_ok=True)

def clean_text(s: str) -> str:
    if not isinstance(s, str): return ""
    s = html.unescape(s)
    s = re.sub(r"<br\s*/?>", " ", s)
    s = re.sub(r"http\S+", " ", s)
    s = s.lower()
    # light contractions
    s = re.sub(r"won't", "will not", s)
    s = re.sub(r"can't", "can not", s)
    s = re.sub(r"n't", " not", s)
    s = re.sub(r"'re", " are", s)
    s = re.sub(r"'s", " is", s)
    s = re.sub(r"'d", " would", s)
    s = re.sub(r"'ll", " will", s)
    s = re.sub(r"'t", " not", s)
    s = re.sub(r"'ve", " have", s)
    s = re.sub(r"'m", " am", s)
    s = re.sub(r"[^a-z0-9\s\.\!,?\']", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def evaluate_binary(y_true, y_pred, y_proba=None) -> Dict[str, float]:
    out = {
        "acc": float(accuracy_score(y_true, y_pred)),
        "f1":  float(f1_score(y_true, y_pred)),
    }
    out["auc"] = float(roc_auc_score(y_true, y_proba)) if y_proba is not None else float("nan")
    return out

# ---- MLflow helpers (safe no-op if mlflow not installed) ----
def start_mlflow_run(run_name: str, experiment: str = "imdb_sentiment", tracking_uri: str = "file:./mlruns") -> bool:
    try:
        import mlflow
        mlflow.set_tracking_uri(tracking_uri)
        mlflow.set_experiment(experiment)
        mlflow.end_run()
        mlflow.start_run(run_name=run_name)
        return True
    except Exception:
        return False

def end_mlflow_run():
    try:
        import mlflow
        mlflow.end_run()
    except Exception:
        pass

def mlflow_log(params: Dict[str, Any] = None, metrics: Dict[str, Any] = None, artifacts: List[str] = None):
    try:
        import mlflow
    except Exception:
        return
    if params:
        try: mlflow.log_params(params)
        except Exception: pass
    if metrics:
        clean = {}
        for k, v in metrics.items():
            try:
                fv = float(v)
                if np.isfinite(fv):
                    clean[k] = fv
            except Exception:
                continue
        if clean:
            try: mlflow.log_metrics(clean)
            except Exception: pass
    if artifacts:
        for path in artifacts:
            try:
                if os.path.isdir(path):
                    mlflow.log_artifacts(path)
                elif os.path.isfile(path):
                    mlflow.log_artifact(path)
            except Exception:
                pass

# -----------------------------
# Data loading
# -----------------------------
def load_data_imdb() -> Tuple[pd.DataFrame, pd.DataFrame]:
    try:
        from datasets import load_dataset
    except Exception as e:
        raise RuntimeError("Install 'datasets' to use --source imdb (pip install datasets).") from e
    ds = load_dataset("imdb")
    tr = pd.DataFrame(ds["train"])
    te = pd.DataFrame(ds["test"])
    tr["text_clean"] = tr["text"].apply(clean_text)
    te["text_clean"] = te["text"].apply(clean_text)
    return tr, te

def load_data_csv(train_csv: str, test_csv: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
    if not (train_csv and test_csv):
        raise ValueError("For --source csv you must provide --train-csv and --test-csv")
    tr = pd.read_csv(train_csv)
    te = pd.read_csv(test_csv)
    if "text_clean" not in tr.columns: tr["text_clean"] = tr["text"].apply(clean_text)
    if "text_clean" not in te.columns: te["text_clean"] = te["text"].apply(clean_text)
    return tr, te

# -----------------------------
# TF-IDF branch
# -----------------------------
def build_tfidf(train_text: List[str], test_text: List[str], max_features: int = 30000):
    vec = TfidfVectorizer(max_features=max_features, ngram_range=(1,2), stop_words="english")
    Xtr = vec.fit_transform(train_text)
    Xte = vec.transform(test_text)
    dump(vec, "vectorizers/tfidf.joblib")
    return vec, Xtr, Xte

def train_gbt(Xtr, Xte, ytr, yte, use_mlflow: bool):
    try:
        from xgboost import XGBClassifier
    except Exception as e:
        raise RuntimeError("Install 'xgboost' to run --run-gbt (pip install xgboost).") from e
    params = dict(
        n_estimators=400, max_depth=7, learning_rate=0.06,
        subsample=0.9, colsample_bytree=0.8,
        tree_method="hist", n_jobs=-1, random_state=SEED
    )
    model = XGBClassifier(**params)
    model.fit(Xtr, ytr)
    p = model.predict(Xte)
    proba = model.predict_proba(Xte)[:, 1]
    metrics = {"model": "GBT", **evaluate_binary(yte, p, proba)}
    dump(model, "models/gbt_imdb.pkl")

    if use_mlflow and start_mlflow_run("GBT_TFIDF"):
        mlflow_log(params={**params, "feature_set":"tfidf"}, metrics=metrics, artifacts=["models/gbt_imdb.pkl"])
        end_mlflow_run()
    return metrics

def train_logreg(Xtr, Xte, ytr, yte, use_mlflow: bool):
    logr = LogisticRegression(max_iter=1000, n_jobs=-1)
    logr.fit(Xtr, ytr)
    p = logr.predict(Xte)
    proba = logr.predict_proba(Xte)[:, 1]
    metrics = {"model": "LogReg", **evaluate_binary(yte, p, proba)}
    dump(logr, "models/logreg_imdb.pkl")

    if use_mlflow and start_mlflow_run("LogReg_TFIDF"):
        mlflow_log(params={"model":"LogisticRegression","feature_set":"tfidf"}, metrics=metrics, artifacts=["models/logreg_imdb.pkl"])
        end_mlflow_run()
    return metrics

def train_mlp_svd(Xtr, Xte, ytr, yte, svd_components: int, use_mlflow: bool):
    from sklearn.neural_network import MLPClassifier
    svd = TruncatedSVD(n_components=svd_components, random_state=SEED)
    Xtr_svd = svd.fit_transform(Xtr)
    Xte_svd = svd.transform(Xte)
    scaler = StandardScaler()
    Xtr_s = scaler.fit_transform(Xtr_svd)
    Xte_s = scaler.transform(Xte_svd)

    mlp = MLPClassifier(hidden_layer_sizes=(256,64), activation="relu", batch_size=256, max_iter=12, random_state=SEED)
    mlp.fit(Xtr_s, ytr)
    p = mlp.predict(Xte_s)
    proba = mlp.predict_proba(Xte_s)[:, 1]
    metrics = {"model": f"MLP(SVD-{svd_components})", **evaluate_binary(yte, p, proba)}

    dump(svd, "vectorizers/svd.joblib")
    dump(scaler, "vectorizers/scaler.joblib")
    dump(mlp, "models/mlp_svd_imdb.pkl")

    if use_mlflow and start_mlflow_run("MLP_SVD"):
        mlflow_log(params={"feature_set":f"svd-{svd_components}","hidden_layers":"(256,64)","max_iter":12},
                   metrics=metrics,
                   artifacts=["models/mlp_svd_imdb.pkl","vectorizers/svd.joblib","vectorizers/scaler.joblib"])
        end_mlflow_run()
    return metrics

# -----------------------------
# Transformer branch (RAM/time-safe)
# -----------------------------
def train_transformer(train_df: pd.DataFrame, test_df: pd.DataFrame, samples: int, epochs: int, use_mlflow: bool):
    os.environ["WANDB_DISABLED"] = "true"
    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
        from datasets import Dataset as HFDataset, DatasetDict
    except Exception as e:
        raise RuntimeError("Install 'transformers' and 'datasets' to run --run-transformer.") from e

    tr = train_df.sample(n=min(samples, len(train_df)), random_state=SEED)
    te = test_df.sample(n=min(samples, len(test_df)), random_state=SEED)

    hf_train = HFDataset.from_pandas(tr[["text_clean","label"]].rename(columns={"text_clean":"text"}))
    hf_test  = HFDataset.from_pandas(te[["text_clean","label"]].rename(columns={"text_clean":"text"}))
    hds = DatasetDict({"train": hf_train, "test": hf_test})

    tok = AutoTokenizer.from_pretrained("distilbert-base-uncased")
    def tokenize(b): return tok(b["text"], truncation=True, padding="max_length", max_length=192)
    tok_ds = hds.map(tokenize, batched=True).remove_columns(["text"]).rename_column("label","labels").with_format("torch")

    from sklearn.metrics import accuracy_score as _acc, f1_score as _f1
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=-1)
        return {"acc": _acc(labels, preds), "f1": _f1(labels, preds)}

    model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)
    args = TrainingArguments(
        output_dir="transformer/model",
        per_device_train_batch_size=8,
        per_device_eval_batch_size=16,
        gradient_accumulation_steps=2,
        num_train_epochs=epochs,
        learning_rate=2e-5,
        logging_steps=100,
        fp16=True,
        report_to="none"
    )
    trainer = Trainer(model=model, args=args,
                      train_dataset=tok_ds["train"],
                      eval_dataset=tok_ds["test"],
                      compute_metrics=compute_metrics)
    trainer.train()
    trm = trainer.evaluate()

    metrics = {
        "model": f"Transformer(DistilBERT,{len(tr)}x{len(te)})",
        "acc": float(trm.get("eval_acc", np.nan)),
        "f1":  float(trm.get("eval_f1",  np.nan)),
        "auc": float("nan"),
    }

    # save artifacts
    model.save_pretrained("transformer/model")
    tok.save_pretrained("transformer/model")

    if use_mlflow and start_mlflow_run("Transformer_DistilBERT"):
        mlflow_log(params={"epochs":epochs,"samples":len(tr),"max_len":192},
                   metrics=metrics,
                   artifacts=["transformer/model"])
        end_mlflow_run()

    return metrics

# -----------------------------
# Orchestration
# -----------------------------
def main(args=None):
    parser = argparse.ArgumentParser(description="IMDB sentiment full pipeline (classic + transformer)")
    parser.add_argument("--source", choices=["imdb","csv"], required=True, help="Data source")
    parser.add_argument("--train-csv", type=str, help="Path to train CSV (if --source csv)")
    parser.add_argument("--test-csv",  type=str, help="Path to test CSV (if --source csv)")
    parser.add_argument("--tfidf-max-features", type=int, default=30000, help="TF-IDF vocab size")

    parser.add_argument("--run-gbt", action="store_true", help="Train Gradient Boosted Trees (XGBoost)")
    parser.add_argument("--run-logreg", action="store_true", help="Train Logistic Regression baseline")
    parser.add_argument("--run-mlp-svd", action="store_true", help="Train MLP using SVD-reduced features")
    parser.add_argument("--svd-components", type=int, default=256, help="SVD components for MLP")

    parser.add_argument("--run-transformer", action="store_true", help="Fine-tune DistilBERT on subset")
    parser.add_argument("--transformer-samples", type=int, default=4000, help="Samples for transformer train/test")
    parser.add_argument("--transformer-epochs", type=int, default=1, help="Transformer epochs")

    parser.add_argument("--use-mlflow", action="store_true", help="Log runs to MLflow (local ./mlruns)")
    parser.add_argument("--save-metrics", type=str, default="reports/metrics.csv", help="Output CSV path")

    args = parser.parse_args(args)
    ensure_dirs()

    # Load data
    if args.source == "imdb":
        train_df, test_df = load_data_imdb()
    else:
        train_df, test_df = load_data_csv(args.train_csv, args.test_csv)

    # Build TF-IDF once for classic models
    _, Xtr, Xte = build_tfidf(train_df["text_clean"].tolist(),
                              test_df["text_clean"].tolist(),
                              max_features=args.tfidf_max_features)
    ytr = train_df["label"].values
    yte = test_df["label"].values

    results = []

    if args.run_gbt:
        results.append(train_gbt(Xtr, Xte, ytr, yte, args.use_mlflow))

    if args.run_logreg:
        results.append(train_logreg(Xtr, Xte, ytr, yte, args.use_mlflow))

    if args.run_mlp_svd:
        results.append(train_mlp_svd(Xtr, Xte, ytr, yte, args.svd_components, args.use_mlflow))

    if args.run_transformer:
        results.append(train_transformer(train_df, test_df, args.transformer_samples, args.transformer_epochs, args.use_mlflow))

    if not results:
        warnings.warn("No models were selected. Use flags like --run-gbt, --run-logreg, --run-transformer.")
        return

    # Save consolidated metrics
    df = pd.DataFrame(results)
    for col in ("acc","f1","auc"):
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0.0)
    df = df.sort_values("f1", ascending=False).reset_index(drop=True)
    df.to_csv(args.save_metrics, index=False)

    print("\n=== Model Comparison (sorted by F1) ===")
    print(df)
    print(f"\nâœ… Saved metrics to {args.save_metrics}")
    print("Artifacts:")
    print("- models/: gbt_imdb.pkl, logreg_imdb.pkl, mlp_svd_imdb.pkl (if trained)")
    print("- vectorizers/: tfidf.joblib, svd.joblib, scaler.joblib (if used)")
    print("- transformer/model/ (if trained)")

if __name__ == "__main__":
    # Pass arguments as a list of strings to simulate command-line execution
    main(["--source", "imdb", "--run-logreg"])